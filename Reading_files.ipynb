{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This file contains functions to read datasets in ARFF format specifically for the following datasets: Chemistry, CS, Philosophy, Chess, Corel5k, Medical, Langlog, Coffee, Yeast, CAL500, Birds, Emotions, Scene, 20NG, and Enron. All datasets can be accessed through the following link: https://www.uco.es/kdis/mllresources/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# CAL500\n",
    "def parse_arff_data_CAL500(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if '{0,1}' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section:\n",
    "                row = np.array([1 if float(val) > 0 else 0 for val in line.split(',')], dtype=int)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    print(data_matrix)\n",
    "    return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# Corel5k\n",
    "def parse_arff_data_Corel5k(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if 'Cluster' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section:\n",
    "                # Split the line by commas and convert to integers\n",
    "                row = np.array([int(val) for val in line.split(',')], dtype=int)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# LLOG\n",
    "def parse_arff_data_LLOG(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if '{0,1}' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section and line.startswith(\"{\") and line.endswith(\"}\"):\n",
    "                row = np.zeros(total_attributes, dtype=int)\n",
    "                entries = line[1:-1].split(',')\n",
    "                for entry in entries:\n",
    "                    index, value = entry.split()\n",
    "                    row[int(index)] = int(value)\n",
    "                data_matrix.append(row)\n",
    "    return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# Chess, cs\n",
    "def parse_arff_data_chess_cs(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if '{0,1}' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section:\n",
    "                # Split the line by commas and convert to integers\n",
    "                row = np.array([int(val) for val in line.split(',')], dtype=int)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# genbase\n",
    "def parse_arff_data_genbase(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if '{YES, NO}' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.lower().startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section and line:\n",
    "                row = []\n",
    "                values = line.split(',')\n",
    "                for value in values:\n",
    "                  if value == ('YES' or 'NO' or '1' or '0'):\n",
    "                    if '{YES, NO}' in line or '{0, 1}' in line:\n",
    "                        # Convert {YES, NO} or {0, 1} to 1 or 0\n",
    "                        row.append(1 if value.strip() == 'YES' or value.strip() == '1' else 0)\n",
    "                    else:\n",
    "                        # Assume numeric attributes, convert to 1 if non-zero, else 0\n",
    "                        row.append(1 if float(value) != 0 else 0)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# Coffee\n",
    "def parse_arff_data_coffee(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if '{0,1}' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section:\n",
    "                # Split the line by commas and convert to integers\n",
    "                row = np.array([1 if float(val) > 0.5 else 0 for val in line.split(',')], dtype=int)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# birds\n",
    "def parse_arff_data_birds(arff_path_train, arff_path_test):\n",
    "  data_matrix = []\n",
    "  feature_names = []\n",
    "  labels = []\n",
    "  total_attributes = 0\n",
    "  in_data_section = False\n",
    "\n",
    "  with open(arff_path_train, 'r') as file:\n",
    "      for line in file:\n",
    "          line = line.strip()\n",
    "          if line.lower().startswith(\"@attribute\"):\n",
    "              parts = line.split()\n",
    "              attr_name = parts[1]\n",
    "              if '{' and '}' in line:\n",
    "                  labels.append(attr_name)\n",
    "              else:\n",
    "                  feature_names.append(attr_name)\n",
    "              total_attributes += 1\n",
    "          elif line.startswith(\"@data\"):\n",
    "              in_data_section = True\n",
    "          elif in_data_section:\n",
    "              # Split the line by commas and convert to integers\n",
    "              row = np.array([1 if float(val) > 0.5 else 0 for val in line.split(',')], dtype=int)\n",
    "              data_matrix.append(row)\n",
    "\n",
    "  in_data_section = False\n",
    "  with open(arff_path_test, 'r') as file:\n",
    "      for line in file:\n",
    "        line = line.strip()\n",
    "        if line.lower().startswith(\"@data\"):\n",
    "              in_data_section = True\n",
    "        elif in_data_section:\n",
    "            # Split the line by commas and convert to integers\n",
    "            row = np.array([1 if float(val) > 0.5 else 0 for val in line.split(',')], dtype=int)\n",
    "            data_matrix.append(row)\n",
    "\n",
    "  return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# emotions\n",
    "def parse_arff_data_emotions(arff_path_train, arff_path_test):\n",
    "  data_matrix = []\n",
    "  feature_names = []\n",
    "  labels = []\n",
    "  total_attributes = 0\n",
    "  in_data_section = False\n",
    "\n",
    "  with open(arff_path_train, 'r') as file:\n",
    "      for line in file:\n",
    "          line = line.strip()\n",
    "          if line.lower().startswith(\"@attribute\"):\n",
    "              parts = line.split()\n",
    "              attr_name = parts[1]\n",
    "              if '{' and '}' in line:\n",
    "                  labels.append(attr_name)\n",
    "              else:\n",
    "                  feature_names.append(attr_name)\n",
    "              total_attributes += 1\n",
    "          elif line.startswith(\"@data\"):\n",
    "              in_data_section = True\n",
    "          elif in_data_section:\n",
    "              # Split the line by commas and convert to integers\n",
    "              row = np.array([1 if float(val) >0 else 0 for val in line.split(',')], dtype=int)\n",
    "              data_matrix.append(row)\n",
    "\n",
    "  in_data_section = False\n",
    "  with open(arff_path_test, 'r') as file:\n",
    "      for line in file:\n",
    "        line = line.strip()\n",
    "        if line.lower().startswith(\"@data\"):\n",
    "              in_data_section = True\n",
    "        elif in_data_section:\n",
    "            # Split the line by commas and convert to integers\n",
    "            row = np.array([1 if float(val) > 0 else 0 for val in line.split(',')], dtype=int)\n",
    "            data_matrix.append(row)\n",
    "\n",
    "  return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# chemistry, philosophy\n",
    "def parse_arff_data_chemistry_philosophy(arff_path):\n",
    "  data_matrix = []\n",
    "  feature_names = []\n",
    "  labels = []\n",
    "  total_attributes = 0\n",
    "  in_data_section = False\n",
    "\n",
    "  with open(arff_path, 'r') as file:\n",
    "      for line in file:\n",
    "          line = line.strip()\n",
    "          if line.lower().startswith(\"@attribute\"):\n",
    "              parts = line.split()\n",
    "              attr_name = parts[1]\n",
    "              if '{0,1}' in line:\n",
    "                  labels.append(attr_name)\n",
    "              else:\n",
    "                  feature_names.append(attr_name)\n",
    "              total_attributes += 1\n",
    "          elif line.startswith(\"@data\"):\n",
    "              in_data_section = True\n",
    "          elif in_data_section:\n",
    "              row = np.array([1 if float(val) > 0 else 0 for val in line.split(',')], dtype=int)\n",
    "              data_matrix.append(row)\n",
    "\n",
    "  return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# yeast\n",
    "def parse_arff_data_yeast(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if 'Class' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section and line:\n",
    "                # Split the line by commas and convert to binary values\n",
    "                row = np.array([1 if float(val) > 0 else 0 for val in line.split(',')], dtype=int)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    return np.array(data_matrix), feature_names, labels\n",
    "\n",
    "# Scene\n",
    "def parse_arff_data_scene(arff_path_train, arrf_path_test):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    categories = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path_train, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if 'numeric' in line:\n",
    "                    feature_names.append(attr_name)\n",
    "                else:\n",
    "                    categories.append(attr_name)\n",
    "                total_attributes += 1\n",
    "\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "\n",
    "            elif in_data_section and line:\n",
    "                # Split the line by commas and convert to integers\n",
    "                row = np.array([1 if float(val) >= 0.5 else 0 for val in line.split(',')], dtype=int)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    in_data_section = False\n",
    "    with open(arrf_path_test, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "\n",
    "            elif in_data_section and line:\n",
    "                # Split the line by commas and convert to integers\n",
    "                row = np.array([1 if float(val) >= 0.5 else 0 for val in line.split(',')], dtype=int)\n",
    "                data_matrix.append(row)\n",
    "\n",
    "    return np.array(data_matrix), feature_names, categories\n",
    "\n",
    "# 20NG, Enron\n",
    "def parse_arff_data_enron_20NG(arff_path):\n",
    "  data_matrix = []\n",
    "  feature_names = []\n",
    "  categories = []\n",
    "  total_attributes = 0\n",
    "  in_data_section = False\n",
    "\n",
    "  with open(arff_path, 'r') as file:\n",
    "      for line in file:\n",
    "          line = line.strip()\n",
    "          if line.lower().startswith(\"@attribute\"):\n",
    "              parts = line.split()\n",
    "              attr_name = parts[1]\n",
    "              if 'numeric' in line:\n",
    "                  feature_names.append(attr_name)\n",
    "              else:\n",
    "                  categories.append(attr_name)\n",
    "              total_attributes += 1\n",
    "\n",
    "          elif line.startswith(\"@data\"):\n",
    "              in_data_section = True\n",
    "          elif in_data_section and line.startswith(\"{\") and line.endswith(\"}\"):\n",
    "              row = np.zeros(total_attributes, dtype=int)\n",
    "              entries = line[1:-1].split(',')\n",
    "              for entry in entries:\n",
    "                  index, value = entry.split()\n",
    "                  if value == '1':  # assuming binary encoding\n",
    "                      row[int(index)] = 1\n",
    "                  else:\n",
    "                      row[int(index)] = int(value)  # assuming numeric encoding\n",
    "              data_matrix.append(row)\n",
    "  return np.array(data_matrix), feature_names, categories\n",
    "\n",
    "# Medical\n",
    "def parse_arff_data_medical(arff_path):\n",
    "    data_matrix = []\n",
    "    feature_names = []\n",
    "    labels = []\n",
    "    total_attributes = 0\n",
    "    in_data_section = False\n",
    "\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"@attribute\"):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1]\n",
    "                if 'Class' in line:\n",
    "                    labels.append(attr_name)\n",
    "                else:\n",
    "                    feature_names.append(attr_name)\n",
    "                total_attributes += 1\n",
    "            elif line.startswith(\"@data\"):\n",
    "                in_data_section = True\n",
    "            elif in_data_section and line.startswith(\"{\") and line.endswith(\"}\"):\n",
    "                row = np.zeros(total_attributes, dtype=int)\n",
    "                entries = line[1:-1].split(',')\n",
    "                for entry in entries:\n",
    "                    index, value = entry.split()\n",
    "                    row[int(index)] = int(value)\n",
    "                data_matrix.append(row)\n",
    "    return np.array(data_matrix), feature_names, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
